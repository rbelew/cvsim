%% LyX 2.3.0 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[english]{achemso}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{babel}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{setspace}
\doublespacing
\usepackage[unicode=true,pdfusetitle,
 bookmarks=true,bookmarksnumbered=false,bookmarksopen=false,
 breaklinks=false,pdfborder={0 0 1},backref=false,colorlinks=false]
 {hyperref}
\hypersetup{
 urlcolor=black}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.

\title{Generalized modeling of interventions across 77 countries}
\newcommand{\noun}[1]{\textsc{#1}}
%% Because html converters don't know tabularnewline
\providecommand{\tabularnewline}{\\}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.
\numberwithin{equation}{section}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.

\usepackage[nomarkers,figuresonly]{endfloat}

\author{Richard K. Belew}
\email{rbelew@ucsd.edu}
\affiliation{Univ. California -- San Diego, La Jolla CA}

\author{Cliff Kerr}
\email{ckerr@idmod.org}
\affiliation{Institute for Disease Modeling, Bellevue, WA}

\author{Jasmina Panovska-Griffiths}
\email{j.panovska-griffiths@ucl.ac.uk}
\affiliation{University College London}

\author{William Waites}
\email{wwaites@tardis.ed.ac.uk}
\affiliation{London School of Hygiene and Tropical Medicine}

\SectionNumbersOn

\pagestyle{myheadings}
\markboth{Generalized models of 77 countries - Draft 16 Mar 20}{Generalized models of 77 countries - Draft 16 Mar 21}

% \DeclareBibliographyCategory{cited}
% \AtEveryCitekey{\addtocategory{cited}{\thefield{entrykey}}}
% \usepackage{filecontents}
% \nocite{*}

\@ifundefined{showcaptionsetup}{}{%
 \PassOptionsToPackage{caption=false}{subfig}}
\usepackage{subfig}
\makeatother

\begin{document}
\noindent \begin{center}
\emph{Draft: 16 Mar 2021}
\par\end{center}
\begin{abstract}
COVID-19 continues to spread around the world and modeling plays an
important role in informing policy \cite{Press1015}. An individual-based
model called Covasim has recently been fit to data regarding confirmed
cases and deaths experience in the United Kingdom during the first
half of 2020, and then used it to evaluate alternative intervention
strategies there \cite{jpg20}. We extend this methodology to consider
data from 77 countries to retrospectively model interventions employed
in the first months of 2020 in these countries. Because the age distribution
of populations is a key feature of the COVID-19 pandemic and contacts
among young people are often age-stratified and may play an especially
important role, we focus here on school closure interventions. 

A Covasim model was built for each country, with its population, age
distribution, disease emergence and school closing dates specified.
The model was then calibrated against data concerning COVID-19 diagnosed
cases and related deaths. All countries' simulations were run with
and without school interventions. Because assumptions regarding background
testing rates being performed are critical to statistics regarding
the number of diagnosed patients, three conditions were considered:
the same \emph{fixed} testing rated was assumed for all countries;
\emph{searching} for an estimated testing rate as part of model calibration;
the actual \emph{data} available. The goal of this \emph{post hoc}
analysis of historical data is to understand the limits of our modeling
tools as we move forward to use them for predictive tasks. We consider
the hypothesis: Does incorporating the additional knowledge of school
interventions into a model makes it a better predictor of data concerning
diagnoses and deaths? 

The calibration of model parameters plays an important role in their
evaluation, and an analysis of methods used to calibrate models is
considered in detail. Experiments using Covariance Matrix Adaptation
Evolution Strategy (CMA-ES) to search for model parameters that allowed
a model to best fit available data, and contrasted with parameters
found using the \noun{pyABC} library to implement Approximate Bayesian
Computation (ABC) techniques which also provided kernal density estimates
(KDE). 

In only one of the 77 countries considered did model parameters using
testing rate data differ significantly from ones using search to calibrate
this value. Incorporation of school intervention in models lead to
significant differences in 22 cases, but surprisingly with only two
having better model fit with intervention modeled. Beyond the KDE
estimates it provides, in most cases \noun{pyABC} proves to be an
even more effective parameter search method than CMA-ES.
\end{abstract}

\section{Introduction}

COVID-19 continues to spread around the world and modeling plays an
important role in informing policy \cite{Press1015}. Here we use
a broad range of countries' experiences to identify robust results
common across them. Comparisons between countries are essential for
the control of COVID-19 \cite{10.1001/jama.2020.6585}

\begin{quotation}

Although international comparisons are often disparaged because of
different data quality and fears of the \textquoteleft ecological
fallacy\textquoteright , if done carefully they can play a major role
in our learning what works best for controlling COVID-19. \cite{10.1093/ije/dyaa108}

... the COVID-19 epidemic shows the need for epidemiology to go back
to its roots---thinking about populations. Studying disease occurrence
by person, place and time (often referred to as \textquoteleft descriptive
epidemiology\textquoteright ) is usually taught in introductory courses,
even if this approach is then paid little attention subsequently.
COVID-19 is a striking example of how we can learn a great deal from
comparing countries, states, regions, time trends and persons, despite
of all the difficulties. \cite{10.1093/ije/dyaa108}

\end{quotation}

\begin{quotation}

Predictive models for large countries, such as the US, are even more
problematic because they aggregate heterogeneous sub-epidemics in
local areas.... Models should also seek to use the best possible data
for local predictions. \cite{10.1001/jama.2020.6585}

\end{quotation}

Covasim is a stochastic agent-based simulator for performing COVID-19
analyses. It depends on two primary parameters, \noun{initInfect},
the number of people initially infected at the start of the contagion,
and a baseline value for $\beta$, the transmission rate from susceptible
to infected individuals. A key feature of Covasim is its modeling
of interaction network ``layers'' distinguishing various settings
(work, school, transport, households, communities) which modulate
$\beta$ differently in these settings. 

With travel restrictions as they were in the spring and summer of
2020, levels of migration across national borders were considerably
smaller than that across state or provincial boundaries. Given the
data available, only models at the level of individual countries and
interventions ordered \emph{nationally} are considered here.\footnote{The absence of a national school closure policy in the United States
is the reason it is not included in this analysis.} Because the age distribution of populations is a key feature of the
COVID-19 pandemic and contacts among young people are often age-stratified
and may play an especially important role, we focus here on school
closure interventions. 

Table \ref{fig:countrySumm} lists the 77 countries included in this
study with their ISO-3 code and name, together with key statistics:
\begin{itemize}
\item population in 2019, from ECDC 
\item the start date for their simulation (when the number of infection
first went above 50)
\item the start and end dates of the school intervention; the ``effective''
start date is different in those cases that the intervention began
before the simulation's start date
\item number of days closed by school interventions, and the fraction of
total simulated days this represents
\end{itemize}
Note that the countries modeled varied in population from just over
a million (EST) to IND with a population of 1.4 billion.

\begin{figure}
\noindent \begin{centering}
\includegraphics[width=0.8\paperwidth]{figs/countrySummTbl}
\par\end{centering}
\caption{\label{fig:countrySumm}Country summary statistics}
\end{figure}

To give a preview of the experiments to be presented, consider the
comparison of two runs presented in Figure \ref{fig:comp-noSchool-SRB}.
This shows six curves summarizing two simulation run for the country
of Serbia (ISO3 code SRB). The two curves in the top left graph show
the simulation's estimate (solid line) and data (boxes) of cummulative
diagnoses during early 2020, the middle graph shows estimated vs.
data on cummulative deaths, and the lowest graph shows the cummulative
number of tests performed. These same curves are repeated for two
different experimental conditions, in this case simulations with and
without school interventions included in the model. Better models
are those whose simulated estimates for diagnoses and deaths have
the best match with available data (cf. Section \ref{subsec:Covasim}).
Section \ref{subsec:dataTR} contrasts models using different bases
for testing, and Section \ref{subsec:Incorporating-school-closure}
contrasts models with and without school closure interventions in
the model. 

\begin{figure}
\noindent \begin{centering}
\includegraphics[width=0.8\paperwidth]{figs/compSchool-fit_SRB}
\par\end{centering}
\caption{\label{fig:comp-noSchool-SRB}Model predictions for SRB, without and
with intervention}
\end{figure}

On their face, because the right simulation's estimates of deaths
is a closer match to data, these results make it seem as if incorporating
school closures in the model is an improvement. This would make us
believe that modeling interventions is worthwhile, and that the model
parameter values ($\beta$ and \noun{initInfect}) associated with
this model should be considered more accurate. But is the difference
between the two models \emph{statistically significant}? Typically,
global optimization of simulation parameters is performed to find
values which minimize model mismatch \cite{10.1371/journal.pcbi.1007893}.
In Section \ref{sec:Appen-CMA-ES-search} we describe the optimization
of Covasim parameters using Covariance matrix adaptation evolution
strategy (CMA-ES). In Section \ref{subsec:calibration} these results
are also put in the probabilistically more sound context of Approximate
Bayesian Computation (ABC). 

As the database supporting infections, deaths and school interventions
during the first months of 2020 recedes into the past, it becomes
increasingly irrelevant to the pandemic situation now. The goal of
this \emph{post hoc} analysis over the broad set of historical data
across many countries is to understand the limits of our modeling
tools as we move forward to use them for analysis of newer data and
predictive purposes.

\section{Results}

The first section below reports on ``base model'' experiments that
do \emph{not} include school intervention, which use \emph{data} for
the testing rate, and which has been calibrated using ABC methods.
Experiments contrasting these models with ones \emph{searching} for
the testing rate are then presented in are in Section \ref{subsec:dataTR},
ones including school interventions in Section \ref{subsec:Incorporating-school-closure},
and ones calibrated using CMA-ES global optization in Section \ref{sec:Appen-CMA-ES-search}
An analysis of the statistical significance of these differences is
considered in Section \ref{subsec:calibration}.

\subsection{Base model}
\begin{itemize}
\item use of ABC on noSchool, trate=data as base case
\item Example country
\item contrasted with trate=srch, school, CMAES
\end{itemize}
Covasim defines the value of a model's fit to be a weighted sum of
the error between its predicted number of diagnoses and deaths related
to COVID-19 and data for these values. Figure \ref{fig:base-fit}
shows the range of resulting model fits across 77 countries, with
lower fitness scores assigned to simulations with a better match of
predictions for the number of diagnoses and deaths. Most countries
have fit values below 150, and the average fit across countries is
91.6, including the poor fit examples of UGA and SGP.

\begin{figure}
\noindent \begin{centering}
\includegraphics[width=0.8\paperwidth]{figs/vdeep-allModelsFit}
\par\end{centering}
\caption{\label{fig:base-fit}Base model fits}
\end{figure}

Figure \ref{fig:base-examples} shows the result of two simulation
for ETH and SGP; ETH fit is one of the best, and SGP is the worst.
For each country, the top two plots capture model behavior relative
to data for the number of diagnoses across the time interval considered.
The bottom plot shows the number of tests given over time. 

\begin{figure}
\noindent \begin{centering}
\includegraphics[width=0.8\paperwidth]{figs/vdeep-minMaxFit}
\par\end{centering}
\caption{\label{fig:base-examples}Base model: COL and SGP}
\end{figure}

Figure \ref{fig:base-keyParam} shows the values of the key \noun{initInfect}
and $\beta$ parameters for all countries. Best KDE estimates for
\noun{initInfect} vary by three orders of magnitude, and those for
$\beta$ vary by a factor of three.

\begin{figure}
\noindent \begin{centering}
\includegraphics[width=0.8\paperwidth]{figs/vdeep-primaryParam}
\par\end{centering}
\caption{\label{fig:base-keyParam}Base model key parameter distribution}
\end{figure}


\subsection{Using available data for testing rate\label{subsec:dataTR}}

A central issue in epidemiological modeling concerns assumptions regarding
the background testing rates on which diagnoses counts are based.
Experiments over countries with data on testing rates (daily testing
counts as a fraction of the country's population) via OWID were contrasted
with average testing rates found via calibration. Figure \ref{fig:dataVsearchTrate}
contrasts the testing rate found via calibration search vs. the data-based
rate, with bubble size reflecting the difference in fitness between
the two models\footnote{Because bubble sizes must be positive, blue bubbles are used to show
improved fitness with calibrated testing rates, red bubbles with data-based
testing rates.}.

\begin{figure}
\noindent \begin{centering}
\includegraphics[width=0.8\paperwidth]{figs/compdataSearchFitness-annote_210316}
\par\end{centering}
\caption{\label{fig:dataVsearchTrate}Testing rate from data vs. calibration}
\end{figure}

The testing rates identified via calibration were generally much larger
(20x) than the data-based values. Two countries, ARE and BHR, had
much higher testing rates reported in the data than the others, with
little difference reflected by their calibrated values. Only the difference
in testing rates for OMN proves signficantly different (cf. Section
\ref{subsec:Statistical-significance}). 

As a baseline, these results were also compared to ones using the
same, constant testing rate (as a fraction of the population tested
per day) of \noun{testing\_rate}=3.3e-4, the average across all countries
with data (shown as a red line in Figure \ref{fig:dataVsearchTrate}).
Simulations using this value for testing rate did not appreciably
change model fit from ones using data-based values (data not shown).

Note that the difference between predicted testing rate and data regarding
this value was \emph{not} used by the calibration process in these
experiments to guide the search for model parameters, although Covasim's
Fit measure could be modified to do so. 

\subsection{Incorporating school closure interventions\label{subsec:Incorporating-school-closure}}

The next set of experiments contrast runs with and without school
closure interventions included in the model. As shown in Figure \ref{fig:intrvnFitDiff},
most models' fits were not changed much by including school intervention.
Since fit is measured using a scale where smaller values mean better
fit, negative differences indicate models which were improved with
interventions modeled, and positive differences indicate poorer fit
when interventions are included. When model fit changed, the model
\emph{without} school intervention modeled was typically superior.
Figure \ref{fig:intrvnFitDiff} also breaks out those countries for
which the different in $\beta$ values between the two models was
found to be significantly different (cf. Table \ref{tab:Countries-with-significant}).

\begin{figure}
\noindent \begin{centering}
\includegraphics[width=0.8\paperwidth]{figs/compSchool_210316-annote}
\par\end{centering}
\caption{\label{fig:intrvnFitDiff}Change in fitness with intervention}
\end{figure}

The example of SRB used in Figure \ref{fig:comp-noSchool-SRB} showed
a slight improvement in fit (difference = -23.6). The dashed lines
in the right-hand figures reflect the beginning and ending dates of
the interventions. ISR is the only other country's model with improved
fitness (difference= -35.3) and significant difference in $\beta$
values. In contrast, the results for ITA shown in Figure \ref{fig:intrvn-badExample-ITA}shows
incorporation of school interventions increased (harmed) the fit most
(difference=196.0). The differences in $\beta$ values was statistically
significant for ITA and all others with fitness differences > 100.

\begin{figure}
\noindent \begin{centering}
\includegraphics[width=0.8\paperwidth]{figs/vdeep_noVSchool_210307-ITA}
\par\end{centering}
\caption{\label{fig:intrvn-badExample-ITA}Intervention change ITA}
\end{figure}


\subsection{Model calibration using ABC and CMA-ES\label{subsec:calibration}}

\begin{quotation}

Calibration is a complex and dark art and cannot be covered fully
here; many books have been written about it and it continues to be
an area of active research. A good review article about calibrating
agent-based models like Covasim is available here \cite{10.1371/journal.pcbi.1007893}.
Calibration is usually expressed as an optimization problem: specifically,
find a vector of parameters $\theta$ that minimizes the mismatch
between the data D and the model $M(\theta)$. \href{https://github.com/InstituteforDiseaseModeling/covasim/blob/master/docs/tutorials/t7.ipynb}{Covasim Tutorial\#7}

\end{quotation}

Computational complexity theory ``...help{[}s{]} us comprehend why
so many practical problems seem to be resistant to efficient solution
by computer'' and warns that for ``total search'' problems such
as this, there can be no guarantee of finding the actual optimum value
\cite{Papadimitriou15881}. 

Initial experiments calibrating Covasim with school intervention data
were done using CMA-ES. The goal of providing a statistical foundation
for model parameters found via calibration, however, subsequently
lead to the use of ABC methods as described in Section \ref{subsec:Calibration-using-ABC}.
The ABC method is motivated there, along with experiments calibrating
a simpler compartmental ODE model to build intuition about ABC search.
The values found by ABC calibration are the ones described in all
preceding experiments. Section \ref{subsec:Statistical-significance}
addresses the statistical signfiicance of the observed differences
across experiments.

Here we begin by putting all the various experimental results into
a common frame by considering their differing values for the calibrated
parameters $\beta$ and \noun{initInfect}. Figure \ref{fig:allCalibParam-SRB}
focuses on SRB, the same example mentioned in the introduction and
Section \ref{subsec:Incorporating-school-closure}. The KDE for these
parameters $\beta$ and \noun{initInfect} found by ABC search are
represented by the highlighted red point. A key advantage of ABC methods
is that they can provide kernel density estimates of the parameters
they find that minimize model fit. For SMC-ABC this requires weighting
samples according to their ``importance'' and then computing credible
intervals of some confidence. Confidence=0.9 error bars on the $\beta$
and \noun{initInfect }of the KDE estimate are also displayed.

\begin{figure}
\noindent \begin{centering}
\includegraphics[width=0.8\paperwidth]{figs/vdeep-compAll-SRB}
\par\end{centering}
\caption{\label{fig:allCalibParam-SRB}Calibrated parameters with credible
intervals - SRB}
\end{figure}

Three other points showing the parameter values $\beta$ and \noun{initInfect}
found and their respective fitnesses in their labels are also shown:
\begin{enumerate}
\item using search to establish the testing rate (vs. the base model's use
of data);
\item incorporating school interventions (vs. not); and 
\item using CMA-ES to discover parameter values (vs. ABC)
\end{enumerate}
The first two experiments also provide KDE estimates, and the error
bars for these are shown. 

The \noun{pyABC} library does not explicitly associate a fitness value
with the KDE parameter estimate\footnote{Specifically: pyabc.visualization.credible.compute\_quantile(vals,
w, 0.5)} and so the \emph{minimum} fitness point found during ABC search is
also shown, and labeled with its fitness. The fitness values shown
in the other labels is similarly taken from the corresponding minimum
fitness. 

\subsection{Statistical significance\label{subsec:Statistical-significance}}

The disjoint error bars in Figure \ref{fig:allCalibParam-SRB} imply
that in the case of SRB, the difference in $\beta$ and \noun{initInfect}
parameters on effects on models with/out school intervention can be
considered statistically significant at the 90\% confidence level.
Across the 77 countries considered, in 22 of them the differences
in $\beta$ satisfied this significance test. 

\begin{table}
\noindent \begin{centering}
\begin{tabular}{|c|c|c|c|c|}
\hline 
ISO3 & KDE\_fit & school\_fit & diff & Beta-KDE\tabularnewline
\hline 
\hline 
ISR & 60.8 & 25.5 & -35.3 & 0.0049\tabularnewline
\hline 
SRB & 55.2 & 31.6 & -23.6 & 0.0044\tabularnewline
\hline 
PSE & 122.9 & 116.8 & -6.1 & 0.0016\tabularnewline
\hline 
GRC & 44.8 & 40.3 & -4.5 & 0.0035\tabularnewline
\hline 
MYS & 37.1 & 44.3 & 7.2 & 0.0030\tabularnewline
\hline 
THA & 94.2 & 101.7 & 7.5 & 0.0029\tabularnewline
\hline 
PRT & 63.9 & 72.8 & 9.0 & 0.0038\tabularnewline
\hline 
SVK & 43.0 & 52.1 & 9.1 & 0.0034\tabularnewline
\hline 
FRA & 108.7 & 126.1 & 17.5 & 0.0053\tabularnewline
\hline 
DEU & 65.2 & 92.4 & 27.1 & 0.0056\tabularnewline
\hline 
NLD & 79.7 & 117.3 & 37.6 & 0.0045\tabularnewline
\hline 
IDN & 24.5 & 65.2 & 40.8 & 0.0047\tabularnewline
\hline 
PHL & 26.5 & 77.5 & 51.0 & 0.0044\tabularnewline
\hline 
GBR & 91.5 & 144.6 & 53.1 & 0.0058\tabularnewline
\hline 
NGA & 24.7 & 84.8 & 60.1 & 0.0047\tabularnewline
\hline 
CAN & 72.5 & 147.8 & 75.2 & 0.0049\tabularnewline
\hline 
IRN & 91.2 & 173.1 & 82.0 & 0.0048\tabularnewline
\hline 
IND & 18.1 & 122.6 & 104.6 & 0.0051\tabularnewline
\hline 
ARG & 12.8 & 119.7 & 106.9 & 0.0055\tabularnewline
\hline 
MEX & 39.6 & 164.9 & 125.3 & 0.0052\tabularnewline
\hline 
CHL & 29.9 & 200.2 & 170.4 & 0.0051\tabularnewline
\hline 
ITA & 104.1 & 300.1 & 196.0 & 0.0055\tabularnewline
\hline 
\end{tabular}
\par\end{centering}
\caption{\label{tab:Countries-with-significant}Countries with significant
differences in $\beta$}

\end{table}

Only two models, for and ISR and SRB, showed improvement in fit with
school interventions of more than 10.

Most but not all of the significant differences observed were in $\beta$
between the base experiment contrasted with school closures. In ARG
the difference was also signficant with respect to the difference
in \noun{initInfect, }and in OMN the difference in $\beta$ was signficant
with respect to the model using calibration vs. data for testing rate.

It is reasonable to hypothesize that longer school closures will make
it easier for models of them to demonstrate signficant differences.
Figure \ref{fig:signifDiffvClosure} orders countries (left-to-right)
based on the fraction of the modeled days had school closures in effect
(cf. \ref{fig:countrySumm}), with blue boxes placed at 1.0 if they
demonstrated a signficant difference in $\beta$, and zero otherwise.
Also plotted is the cummulative fraction of countries that showed
signficant differences at that closure level.\footnote{The many red points along the vertical axis correspond to the 30 countries
closed during the entire period.} 

\begin{figure}
\noindent \begin{centering}
\includegraphics[width=0.8\paperwidth]{figs/signifDiffVclosurePeriod}
\par\end{centering}
\caption{\label{fig:signifDiffvClosure} Impact of closiure period on statistical
significance}
\end{figure}

Examples of four countries (highlighted in Figure \ref{fig:signifDiffvClosure})
are shown below. ARG is one of 30 countries that had school closures
during the entire period modeled, and one of the four demonstrating
a signficant difference in $\beta$. DEU showed significant difference
even though schools there were open 68.6\% of the time. GBR schools
were closed 52.7\% of the time, and THA schools 37.3\% of the time.
As mentioned above, for ARG the difference in \noun{initInfect }is
also signficant, while in DEU the value of \noun{initInfect }in models
with/out school closure is nearly identical.

\begin{figure}
\noindent \begin{centering}
\includegraphics[width=0.8\paperwidth]{figs/signifDiff-4examples}
\par\end{centering}
\caption{\label{fig:signifDiffExamples} Examples of statistical significance
in $\beta$ }
\end{figure}


\subsection{Difference with CMA-ES calibrated values}

As discussed above, model calibration using ABC methods brings with
it the virtue of an estimate of the the parameters found are the best
KDE. However, other global optimization methods may be more successful
at discovering well-fitting model parameters, without any claims regarding
posterior estimates. The results of CMA-ES can be compared in terms
of their discovery of better or worse model fits; this distribution
is shown in Figure \ref{fig:cmaesVabc}. In most cases, the model
fit using KDE parameters was about the same as using CMA-ES values.
On average, however the pyABC calibration methods found better fitting
model parameters, sometimes significantly better.

\begin{figure}
\noindent \begin{centering}
\includegraphics[width=0.8\paperwidth]{figs/CMAESvABCFitDist}
\par\end{centering}
\caption{\label{fig:cmaesVabc} CMA-ES vs ABC search}
\end{figure}

The parameters of those models with better CMA-ES fit are worth comparing
to the KDE parameters. Figure \ref{fig:cmaesAlt-KAZ} shows the example
of KAZ which with a model fitting slightly better (difference = -21.3)
does so with values (marked with a large X in the figure) outside
the confidence interval associated with the KDE parameters. . Only
11 differences of this ``semi-significant'' sort\footnote{Recall that no confidence intervals can be associated with the CMA-ES
parameters.} are found across all countries' models, and these are listed in Table
\ref{tab:CMA-ES-superior-fitness}.

\begin{figure}
\noindent \begin{centering}
\includegraphics[width=0.8\paperwidth]{figs/vdeep-compAll-KAZ}
\par\end{centering}
\caption{\label{fig:cmaesAlt-KAZ} CMA-ES alternative - KAZ}
\end{figure}

\begin{table}
\noindent \begin{centering}
\begin{tabular}{|c|c|c|c|c|}
\hline 
ISO3 & Fit diff & param & KDE value & CMA-ES value\tabularnewline
\hline 
\hline 
ARE & -12.8 & initInfect & 8760 & 2761\tabularnewline
\hline 
BHR & -35.5 & initInfect & 2302 & 1001\tabularnewline
\hline 
CAN & -22.0 & initInfect & 32197 & 49833\tabularnewline
\hline 
KAZ & -21.3 & beta & 0.00517 & 0.00632\tabularnewline
\hline 
KAZ & -21.3 & initInfect & 4035 & 1000\tabularnewline
\hline 
LBY & -16.3 & beta & 0.00437 & 0.00562\tabularnewline
\hline 
MEX & -12.1 & initInfect & 36659 & 49917\tabularnewline
\hline 
PSE & -12.5 & beta & 0.00161 & 0.00432\tabularnewline
\hline 
PSE & -12.5 & initInfect & 2428 & 1000\tabularnewline
\hline 
SLV & -30.8 & beta & 0.00433 & 0.00527\tabularnewline
\hline 
TGO & -12.6 & beta & 0.00238 & 0.00397\tabularnewline
\hline 
\end{tabular}
\par\end{centering}
\caption{\label{tab:CMA-ES-superior-fitness}CMA-ES superior fitness }

\end{table}


\section{Methods}

\subsection{Data sources\label{subsec:Data-sources}}

The ECDC was used as the primary organizing data source. ISO3 codes
were used to identify and merge country data.\footnote{Two countries missing from ECDC lists, TWN and HNG. 2019 population
populations for these two was obtained from 'pop19': 23773876 \}\href{https://www.worldometers.info/world-population/}{WorldOMeters} }
\begin{itemize}
\item \href{https://www.ecdc.europa.eu/sites/default/files/documents/COVID-19-geographic-disbtribution-worldwide-2020-08-04.xlsx}{ECDC}
\item \href{ttps://github.com/owid/covid-19-data/blob/master/public/data/testing/covid-testing-all-observations.csv}{OWID testing}\cite{owidcoronavirus}
\item \href{http://en.unesco.org/sites/default/files/covid_impact_education.csv}{UNESCO interventions}
\item \href{http://github.com/OxCGRT/covid-policy-tracker/blob/master/data/OxCGRT_latest_responses.csv}{OxCGRT interventions}
\item Age distribution data from the \href{https://github.com/neherlab/covid19_scenarios/blob/master/src/assets/data/country_age_distribution.json}{Neher Lab}
as distributed as part of Covasim\footnote{cf. \texttt{covasim.data.country\_age\_data.py}}
\end{itemize}
\begin{figure}
\noindent \begin{centering}
\includegraphics[height=3in]{figs/dataSources-v2}
\par\end{centering}
\caption{\label{fig:Data-sources}Data sources}
\end{figure}

Only countries with populations greater than one million were considered,
and the start date for each countries' simulation was picked to begin
when data showed the number of infections went above 50.

\subsubsection{School interventions}

Preliminary experiments used a database of interventions developed
by a database of international intervention specifics called \href{https://github.com/amel-github/covid19-interventionmeasures}{Covid-19 Control Strategies List},
developed by Amélie Desvars-Larrive and colleagues {[}\href{https://www.csh.ac.at}{Complexity Science Hub Vienna}{]}.
This data includes a fine-grained analysis of which school levels
(kindergarten, primary, secondary, university) were ordered closed,
and therefore supported fine-grained variations in the age distributions
of the sort used effectively by Covasim's population generator. 37
countries were included in this data.

The experiments reported here used instead a \emph{consensus} database
of school closures coming from two distinct data sources, OxCGRT and
UNESCO. While broadly consistent, their respective accounts as to
just when individual countries were closed nationally was not identical.
Figure \ref{fig:overlapIntervnData} shows two countries' examples:
BHR, a country with exactly overlapping accounts and DNK with more
discordant ones. The graphs each show two plots of when school closures
were in effect (a value of 1, vs. 0 when not in effect) as described
by a source.

\begin{figure}
\noindent \begin{centering}
\includegraphics[width=0.4\paperwidth]{figs/BHR_ox-unesco_educIntrvn}
\includegraphics[width=0.4\paperwidth]{figs/DNK_ox-unesco_educIntrvn}
\par\end{centering}
\noindent \centering{}\caption{\label{fig:overlapIntervnData}Overlapping intervention data}
\end{figure}

The specification of school closures used in these experiments was
conservative: Only intervention periods that were identified by \emph{both}
sources, for periods of at least 14 days were considered. All countries'
simulatons were begun on this date (between February 14 and May, 22,
2020; cf. Figure \ref{fig:countrySumm}), interventions of some period
(14-150 days) were applied, and all simulations were terminated at
July 31, 2020.

\subsubsection{Testing rate data}

Testing data from OurWorldInData \cite{owidcoronavirus} was used.
For the comparisons in Section \ref{subsec:dataTR}, this daily testing
data was converted to an average testing rate using the country's
population and averaging across the time period of the simulation.

\subsection{Covasim\label{subsec:Covasim}}

Covasim \cite{Kerr2020.05.10.20097469} is an open-source agent-based
(a.k.a. individual-based) model that uses demographic information
on age structure and population size to build realistic transmission
networks within distinct social layers. It allows age-specific disease
outcomes, intrahost viral dynamics, and the ability to incorporate
many sorts of interventions affecting these model elements. 

The basic model requires specification of two key parameters, the
initial number of infected individuals in the population, and $\beta$,
the transmission rate from susceptible to infected individuals. The
global $\beta$ parameter is proposed by the calibration optimizer,
then enhanced/attenuated across individual network layers according
to parameters based loosely on time-use surveys that track how many
hours a week people spend in various settings (work, school, transport,
etc), with households getting an additional multiplier for closeness
of contact. 

Better models are those whose simulated estimates for diagnoses and
deaths are closer to available data. In experiments here we used Covasim's
default \href{https://docs.idmod.org/projects/covasim/en/latest/tutorials/t7.html?highlight=fit\#The-Fit-object}{Fit measure}
(normalized absolute difference) of mismatch. As data regarding deaths
is believed to generally more accurate than that about positive diagnoses,
Covasim uses a weighted sum of error with death rates weighted twice
as heavily as diagnoses.

School closures are modeled as a simple on/off: school closings start/stop
on a specified dates, and layer-specific values for $\beta$ are enhanced
or attenuated. Following \cite{jpg20}, infection rate was set very
low within the schools level, increased within the home level, and
lowered significantly in work and community levels. The net values
for $\beta$ incorporating both default Covasim values and the result
of school interventions are shown in Table \ref{tab:beta-levels}.

\begin{table}
\noindent \begin{centering}
\begin{tabular}{|c|c|c|c|}
\hline 
$\beta$  & Covasim & Intervention & Net with intervention\tabularnewline
\hline 
\hline 
Home & 3.00 & 1.29 & 3.87\tabularnewline
\hline 
School & 0.60 & 0.02 & 0.01\tabularnewline
\hline 
Work & 0.60 & 0.20 & 0.12\tabularnewline
\hline 
Community & 0.30 & 0.20 & 0.06\tabularnewline
\hline 
\end{tabular}
\par\end{centering}
\caption{\label{tab:beta-levels}Per-level $\beta$ values}
\end{table}


\subsection{Calibration using CMA-ES\label{subsec:Calibration-using-CMA-ES}}

Covariance matrix adaptation evolution strategy (CMA-ES) \cite{hansen2016cma}
is a library for stochastic optimization over continuous domains of
non-linear, non-convex functions. The ``ES'' refers to ``Evolutionary
strategy,'' a type of evolutionary computation using the metaphors
of populations and generations, and distinguished by adaptive rates
of mutation across generations. The CMA library has a ``tell-ask''
interface that allows easy bundling of parallel executions of a population
alternative values in each generation. The initial range of mutation
$\sigma_{0}$ was set to 0.1, and the initial search range for all
parameters was set to one quarter of the range between their upper
and lower bounds.

CMA-ES was used as one calibration outer-loop around the basic Covasim
simulation to search for key parameter values that allow the model
to best fit against data. To make computational effort comparable
to the approximately 8000 model evaluations used in experiments with
\noun{pyABC}, 67 generations of 120 individuals = 8040 trials total
were allocated to find the search for parameter values causing the
model to best fit the data. Optimization is always over two parameters,
$\beta$ and \noun{initInfect}, the number of initial infections.
Initial search bounds for the optimization were set:
\begin{itemize}
\item \noun{initInfect}: best = 21000, lower bound =16000, upper bound=26000
\item $\beta$: best = .005, lower bound = 0.001, upper bound=0.01
\end{itemize}
In the experiments described in Section \ref{subsec:dataTR}, a third
parameter corresponding to testing rate is also included. Bounds on
its search were established using the data for the 77 countries available:
\begin{itemize}
\item testingRate: best=3.3e-4, lower bound = 2e-6, upper bound=3e-3
\end{itemize}

\subsection{Calibration using ABC\label{subsec:Calibration-using-ABC}}

Bayesian methods are distinguished by their inference of a posterior
distribution for some set of parameters $\theta$ from the likelihood
of observed data given these values $\pi(y|\theta)$ and estimation
of the parameters prior to using any data $\pi(\theta)$:

\[
\pi(\theta|y)\,\propto\pi(y|\theta)\,\pi(\theta)
\]

Many issues arise (e.g., determining the normalization constant) in
translating this probabilistic strategy into an empirical estimate,
but a deeper issue concerns models with ``hidden'' variables not
reflected in observable data. The basic Bayesian inference can be
extended to consider hidden variables $x$ using the joint likelihood
of the data with these variables $\pi(y,x|\theta)$:

\[
\pi(\theta,x|y)\,\propto\pi(y,x|\theta)\,\pi(\theta)
\]

Simulations like Covasim can, when given input parameters $\theta$,
provide samples of data and hidden variable values from the joint
likelihood function. Sampling methods like Markov Chain Monte Carlo
(MCMC) can then provide numerical estimates for the posterior distribution.
Approximate Bayesian Computation versions of MCMC (ABC-MCMC) proceed
by iteratively selecting ``particles'' (simulations run with parameters
$\theta_{i}$) that produce predictions $z_{i}$ that are required
to be closer $||y-z_{i}||<\epsilon$ to observed data, rejecting those
that are not, and resampling \cite{mckinley2018}. Sequential Monte
Carlo ABC (SMC-ABC) techniques specify a transition kernel for generating
new parameters to test and a method for reducing $\epsilon_{t}$ over
iterations \cite{10.1093/bioinformatics/btp619}.

\noun{pyABC} provides a Python implementation of SMC-ABC supporting
parallel execution of simulations on multicore hardware \cite{10.1093/bioinformatics/bty361}.
Simulations were given a uniform prior distribution over the same
bounds used for CMA-ES optimization. Other parameters control resources
allocated to SMC-ABC search such as the maximum number of ``generations''
of search reducing $\epsilon_{t}$, an absolute minimum on $\epsilon_{t}$,
etc.

Figure \ref{fig:pyABC-search} gives a sense of the search performed
by \noun{pyABC, }in this case for SRB. \ref{fig:pyABC-search}.a shows
the converging posterior estimates for $\beta$ and \noun{initInfect
}over the nine generations of search, and \ref{fig:pyABC-search}.b
shows the declining $\epsilon_{t}$ used to drive the search to better
and better fitting models.

\begin{figure}
\noindent \begin{centering}
\subfloat[Posterior history]{\includegraphics[width=0.4\paperwidth]{figs/SRB-history}

}\subfloat[Epsilon convergence]{\includegraphics[width=0.4\paperwidth]{figs/SRB-epsilon}

}
\par\end{centering}
\caption{\noun{\label{fig:pyABC-search}pyABC }search for SRB parameters}
\end{figure}


\section{Conclusions}

Experiments reported consider a standardized modeling approach applied
across a broad range of countries. The countries were selected because
they had available data on both nation-wide school closures and testing
rates during the early, dynamic days of the pandemic in early 2020
when strategies varied widely and the impact of these interventions
can be imagined to have large impact. It was expected that incorporating
school interventions into models would allow them to better fit data
concerning deaths and diagnoses, but generally that was not found
to be the case; restricting attention to only models with statistically
significant difference in parameters only SRB and ISR showed improved
fitness. Similarly, it was expected than making use of data on testing
rates within countries would lead to better models than assuming a
constant testing rate or allowing calibration to set testing rates
at levels that lead to better fitting models. While calibrated testing
rates did differ considerably from data-based values, differences
in the resulting models did not generally lead to better fit with
deaths and diagnosis data and in only one case (OMN) lead to models
with significantly different parameter values. 

A comparison of global CMA-ES optimization techniques to Bayesian
SMC-ABC calibration using the \noun{pyABC} library showed broadly
consistent results in the parameter values discovered by the two methods,
but also that \noun{pyABC} was generally even more effective at calibrating
Covasim model parameters than CMA-ES.

\subsection{Scientific sharing, publishing and open source models}

\begin{quotation}

Early models relied on sparse, sometimes unreliable, data, and modelers
did not anticipate the emergence of important new facts.... For use
in an emergency, models developed through basic research need to be
\textquotedblleft operationalized\textquotedblright ---that is, made
robust for evaluating specific policy interventions. \textquotedblleft Nowcasting\textquotedblright{}
requires models that integrate incomplete, real-time data and emerging
medical knowledge to provide situational awareness.... Models must
also incorporate behavioral responses to policy interventions that
may change the course of an epidemic. \cite{Press1015}

\end{quotation}

Traditional compartmental models represent the core of epidemiological
prediction efforts, but become constrained as more fine-grained compartments
are considered. Models like Covasim bring the expressive power of
agent-based desciptions of behaviors over networks to allow evaluation
of many varieties of intervention strategies and empirical testing
against many data sources, but are more difficult to make statistical
inferences about. 

Well-engineered, open source codebases like Covasim and pyABC allow
independent model components to be investigated and incorporated separately.
Basic agent-based models can be related directly to traditional ODE
compartmental model analogs. The publishing of full model implementation
details, like those included with the Panovska-Griffiths publication
\cite{jpg20} and \href{https://github.com/Jasminapg/Covid-19-Analysis}{code repository}
provide an excellent example. Careful experimentation building from
agent-based models may extend the results into mathematically intractable
regimes inaccessible to simpler ODE mdels. The COVID-19 pandemic,
and others to come, demand fast-paced scientific sharing that is catalyzed
by such interactions.

\pagebreak{}

\bibliographystyle{achemso}
\bibliography{covid}

\end{document}
